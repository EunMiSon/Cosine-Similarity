{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunMiSon/Cosine-Similarity/blob/main/%ED%95%AD%EB%AA%A9_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wY4Yp6JM-PmJ"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US0Tm3oH_gOP",
        "outputId": "522f9e10-1c2c-43e4-f800-861bf44e50c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7fUzxba_oej",
        "outputId": "bed9b74e-1ae8-47fe-9294-7740762069d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWcBPnL_sym",
        "outputId": "9a72e03e-ec74-4345-e023-afe6c452d475"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkzOE33E_wZP",
        "outputId": "e1a5fd7e-89fa-48cb-abcf-045200caf170"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "aFnhXmwp-Qta"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "7ddtD9Ws-S3J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Vb9w4Wg3-UK4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플1과 비교"
      ],
      "metadata": {
        "id": "_DEjM2VgpS-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample paragraphs\n",
        "paragraph1 = \"Personal information items collected: Name, date of birth, gender, login ID, password, home phone number, mobile phone number, e-mail, and information of legal representative for subscribers under the age of 14\"\n",
        "sample1 = \"category Email (ID(*1), password, nickname, profile picture List of friends Contact (at least one of email and phone number is required) Email, password, nickname, profile picture, friend list, contact, service usage, in-service purchase and payment history\""
      ],
      "metadata": {
        "id": "0VGN0gcK-eGF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "_O1IFkvW_atp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample1 = preprocess(sample1)"
      ],
      "metadata": {
        "id": "envLvtUO_dQQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample1])"
      ],
      "metadata": {
        "id": "NrytSmlm_06f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "AyL6Fkjp_3Yy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVQo4yh_4i1",
        "outputId": "73b2ff8c-74d7-4a08-dae4-62946b097e7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.13944990495085496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플2와 비교"
      ],
      "metadata": {
        "id": "3ywogA9PAS9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample2 = \"Items of personal information to be processed A. The company is processing the following personal information items. Distinguished Processing Purpose Required/Select Collection Item Retention Period Membership and membership management [Membership] - Identification of members through identification based on the use of membership services - Limiting the number of duplicate memberships Mandatory ID, password, name, date of birth, identity information, and duplicate subscription information (select mobile phone number or email address) [When registering as a member under the age of 14] The legal representative's name, mobile phone number, until he/she withdraws from the membership Choice - Mobile phone or email address other than gender, phone number, and identity verification - School name (if a student member) - Performance information, admission information, grade, and affiliation (when using the admission information service) - Address (when ordering textbooks and supplies) [Membership management] - Prevention of Unauthorized Use and Unauthorized Use of Defective Members - Communicate disclaimers Required ID, password, name, date of birth, personal identification information (choose from mobile phone number or email address) Until membership is withdrawn [Customer consultation] - Preserving records for dispute settlement - Complaint handling, complaint handling, customer consultation Required name (guardian, student), mobile phone number (guardian, student), email address, phone number, grade, 3 years of affiliation Engagement fulfillment and service delivery - Content Delivery - Purchases and Charges - Identification of the purchase of content - Postal delivery, delivery of goods, bills, etc - Customized entrance examination and provision of admission data Required name, contact number, address, email, payment method, bank name, account number 5 years Selective cash receipt issue information (mobile phone number) 5 years - The data subject may refuse to agree to the items and methods of collecting personal information collected by the company, and if refused, part of the use of services provided to members may be restricted. * In case of refusal of collection: Only non-members can use free content * When collection is allowed: Contract implementation and service provision (paid content, entrance examination counseling, etc.) B. The following information may be generated and collected during the process of using the information service or the process of processing the business Processing Purpose Personal Information Item Retention Period Prevention of Unauthorized Use and Prevention of Unauthorized Use Service usage records, access logs, cookies, access IP information, access device information, bad usage records Period of legal obligations upon withdrawal from membership * For cookies, expiration at browser exit or logout Payment History Bank/Card Company Code, Approval Number Period of legal obligations upon withdrawal from membership * For cookies, expiration at browser exit or logout - Collection methods: Home page (member registration, consultation bulletin board, public bulletin board, etc.), written form, membership registration through phone/fax, prize event application, delivery request\""
      ],
      "metadata": {
        "id": "1u8wz702_80f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "QXSlLJa0AJfl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample2 = preprocess(sample2)"
      ],
      "metadata": {
        "id": "DMBQEFoXALSu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample2])"
      ],
      "metadata": {
        "id": "jOM7x3VUAFjc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "84g-HzgDAPpN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq2Q60cpAQtJ",
        "outputId": "961647e5-0131-4d83-c06d-0c26bd611f21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.4460901533598196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플 3과 비교"
      ],
      "metadata": {
        "id": "FPZpmLZfcMR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample3 = \"Personal Information Collection ItemsDomestic resident membership (aged 14 or older)Required items: ID, password, name, gender, date of birth, e-mail, identification value (ci, di)Optional: Address, landline, mobile phoneDomestic resident membership (under 14 years of age)Required items: ID, password, name, gender, date of birth, e-mail, identification value (ci, di), legal representative's name, date of birth, identification value (ci, di), e-mailOptional: Address, landline, mobile phoneForeigners living in Korea sign up for membershipRequired items: ID, password, name, gender, date of birth, e-mail, identification value (ci, di), countryOptional: Address, landline, mobile phoneOverseas resident/foreigner membershipRequired items: ID, password, name, gender, date of birth, email, country, social security number (personal identification information)Optional: Address, landline, mobile phoneIdentification of yourselfName, gender, date of birth, name of legal representative, gender, date of birth, etcDuring the service use process, service usage records such as cookies, access logs, and access device information can be automatically generated and collected.\""
      ],
      "metadata": {
        "id": "mAm9QnvHcDhe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "NB0revVhcz4j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample3 = preprocess(sample3)"
      ],
      "metadata": {
        "id": "-klM1SY2c16W"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample3])"
      ],
      "metadata": {
        "id": "xx9H655Sc8JB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "-hskRmUmc_HK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nK5s9fedA52",
        "outputId": "35f97d54-96ed-472b-c265-67833f021831"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.41617875694689765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플4와 비교"
      ],
      "metadata": {
        "id": "L-UVKqkqdc22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample4 = \"<Scope of items of personal information to be collected and The personal information collected by the company from members at the time of membership is as follows to provide services such as membership registration, counseling, and service application and to fulfill the contract. 1) Collect e-mail, name, date of birth, age, gender, profile picture, identification token, member number (only for members using SNS-linked or affiliated plan) and add legal representative information (name, date of birth, gender, duplicate registration information (DI, mobile phone) if the member's birth date is under the age of 14. Personal information collected from users during the service use process is as follows. 1) If a member wants to use a paid service, the company can collect the information necessary for payment as follows at the time of payment. - Payment method owner information (name), card information, mobile phone number, landline phone number, transaction ID issued for each payment, payment product code 2) The company may collect the following information if a member participates in an event or promotion. - Name, email address, mobile phone number, address, date of birth 3) Self-certification is conducted to restrict the use/purchase of contents and products according to age and to prevent fraudulent use of services, and name, date of birth, gender, domestic/foreigner status, mobile phone number, linked information (CI), and duplicate confirmation information (DI) can be collected. 4) When you refund cash, you can collect the depositor's name, account bank name, account number, and relationship document (if necessary). 5) When inquiring to the customer center, information such as email address, mobile phone number, name, date of birth, and payment information can be collected for accurate information. 6) For the purpose of providing customized recommendation services for members, behavioral information such as information on services that cannot identify users, access time, and frequency can be collected. The following information can be generated and collected during the service use process. 1) PC: PC MacAddress, PC specification information, browser information, and program version information used when using other services 2) Mobile phone (smartphone) & smart OS-based mobile device (Tablet PC, etc.) : Model name, unique number for each device (UDID, IME, etc.), OS information, mobile carrier, Google/Apple advertisement ID 3) Other information: service usage (stop) history, access log, cookies, access IP information\""
      ],
      "metadata": {
        "id": "0dWyKbNMdgjO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "YDk9rVxTdlm_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample4 = preprocess(sample4)"
      ],
      "metadata": {
        "id": "77Ipg7uEdnbC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample4])"
      ],
      "metadata": {
        "id": "DSzPsxp_oxkc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "sEr09wQ4drIm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhT6bSgvdv2b",
        "outputId": "e12a589a-e977-45de-c495-e13e4252381c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.5316217605068895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플5와 비교"
      ],
      "metadata": {
        "id": "VYZRDeyHdwpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample5 = \"Items and methods of collecting personal information On the Nowon-gu website, the following information is collected by dividing it into essential information for providing basic member services and optional information for providing services tailored to the preferences and needs of each information subject. There is no limit to the use of the service even if you do not enter the selection information for the subscription information. (However, in services that require identity verification, there may be restrictions on the use of services if identity verification is not performed.) A. Items of personal information to be collected - Required items: ID, password, name, gender, address, mobile phone, e-mail, subscription authentication information, legal representative authentication information (for children's members) - Optional items: Phone, job, notification application, items of interest B. Information automatically collected by the computer - If you use the homepage, the date and time of visit, cookies, access IP, subscription path, and browser type are automatically collected and stored through the login history. C. How to collect personal information: Online reservation application such as membership registration on the website and Internet recruitment\""
      ],
      "metadata": {
        "id": "ps3Xw-DjdzDV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the paragraphs\n",
        "def preprocess(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # remove stop words\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    # lemmatize\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # join tokens back into text\n",
        "    text = \" \".join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Qs2Ue_4Fd5Rd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph1 = preprocess(paragraph1)\n",
        "sample5 = preprocess(sample5)"
      ],
      "metadata": {
        "id": "l3ll1SSgd6z0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the paragraphs using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_paragraphs = vectorizer.fit_transform([paragraph1, sample5])"
      ],
      "metadata": {
        "id": "OB-7dPxHo7fe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity between the paragraphs\n",
        "similarity = cosine_similarity(vectorized_paragraphs)[0][1]"
      ],
      "metadata": {
        "id": "qA3Ss6ETd-J1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQD5hBwd_TL",
        "outputId": "cba77bd1-5923-4f93-ed88-0892d4e83f56"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: 0.37727363098867256\n"
          ]
        }
      ]
    }
  ]
}